---
title: "R cheatsheet - Data Processing"
output: html_notebook
---
# 2. Data Processing 
## 2.1 Basic Subset dataframe
```{r}
x <- data.frame(c(1:10),letters[1:10],LETTERS[1:10])
#subsetting rows throught logic value
TF <- x[,1] >5
x[TF,]
x[x$c.1.10.>5,]
subset(x,c.1.10. > 5)
#subset columns 
x[,2:3]
```

## 2.2 Data table is more efficient ofr data procession

```{r}
# data table, more efficient
library(data.table)
set.seed(45L)
DT <- data.table(V1=c(1L,2L),V2=LETTERS[1:3],
                 V3=round(rnorm(4),4),V4=1:12)

# subsetting rows
DT[3:5,] 
DT[3:5]
DT[ V2 == "A"] 
DT[ V2 %in% c("A","C")]

#Manipunating colums
DT[,V2]
DT[,.(V2,V3)] #.() is the alias for list()

# aggregation with 
DT[,sum(V1)]
DT[,.(sum(V1),sd(V3))]
DT[,.(Aggregate = sum(V1), Sd.V3 = sd(V3))]

#select  column v1, and calculate the sd of v3
DT[,.(V1, Sd.V3 = sd(V3))] 

#Multiple expressions can be wrapped in curly braces.
DT[,{print(V2)
plot(V3)
NULL}]

# group by
DT[,.(V4.Sum = sum(V4)),by=V1]
DT[,.(V4.Sum = sum(V4)),by=.(V1,V2)]
DT[,.(V4.Sum = sum(V4)),by=sign(V1-1)]
DT[,.(V4.Sum = sum(V4)),by=.(V1.01 = sign(V1-1))]

# group only a subset
DT[1:5,.(V4.Sum = sum(V4)),by=V1]

# Count
DT[,.N,by=V1]

# ADDING/UPDATING COLUMNS BY REFERENCE IN USING :=
(DT[, V1 := round(exp(V1),2)]) #update the value of V1)
(DT[, c("V1","V2") := list(round(exp(V1),2), LETTERS[4:6])])
DT[, ':=' (V1 = round(exp(V1),2), V2 = LETTERS[4:6])][]
DT[, V1 := NULL][] # delete

# Set key
set.seed(45L)
DT <- data.table(V1=c(1L,2L),V2=LETTERS[1:3],
                 V3=round(rnorm(4),4),V4=1:12)
setkey(DT,V2)
DT["A"]
DT["A", mult ="first"]
DT["A", mult ="last"]

# Returns all the rows where the key column (V2) has the value A or D. A is found, D is not so NA is returned for D.
DT[c("A","D")]
DT[c("A","D"), nomatch = 0]

DT[c("A","C"), sum(V4)]
# Returns one total sum of column V4, for the rows of the key column (V2) that have values A or C.
DT[c("A","C"), sum(V4), by=.EACHI]
```

## 2.3 dplyer package

dplyr can work with data frames as is, but if you’re dealing with large data, it’s worthwhile to convert them to a `tbl_df`: this is a wrapper around a data frame that won’t accidentally print a lot of data to the screen.

Dplyr aims to provide a function for each basic verb of data manipulation:
* `filter()` (and slice())
* `arrange()`

arrange() works similarly to filter() except that instead of filtering or selecting rows, it reorders them. It takes a data frame, and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns:


* `select()` (and `rename()`)
* `distinct()`
* `mutate()` (and `transmute()`)
* `summarise()`
* `sample_n()` (and `sample_frac()`)

```{r}
library(nycflights13)
library(dplyr)
dim(flights)
head(flights)
flights <- tbl_df(flights)

# filter to subset
filter(flights, month == 1, day == 1)
filter(flights, month == 1 | month == 2)

# Select rows by slice
slice(flights, 1:10)
slice(flights, c(1,3,5,6))

#Arrange rows with arrange()
arrange(flights, year, month, day)
arrange(flights, desc(arr_delay))

#Select columns with select()
# Select columns by name
select(flights, year, month, day)
select(flights, year:day)
# Select all columns except those from year to day (inclusive)
select(flights, -(year:day))
# You can rename variables with select() by using named arguments:
select(flights, tail_num = tailnum)
flights
# Or we can use rename
rename(flights, tail_num = tailnum)
#Extract distinct (unique) rows. Use distinct()to find unique values in a table:
distinct(flights, tailnum)
distinct(flights, origin, dest)
#(This is very similar to base::unique() but should be much faster.)

#Add new columns with mutate()
mutate(flights, gain = arr_delay - dep_delay, speed = distance / air_time * 60)

#The key difference between mutate() and transform() is that mutate allows you to refer to columns that you’ve just created
mutate(flights, gain = arr_delay - dep_delay, gain_per_hour = gain / (air_time / 60))

#If only want to keep the new variables, use transmute():
transmute(flights, gain = arr_delay - dep_delay, gain_per_hour = gain / (air_time / 60))

#Summarise values with summarise()
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))


# Randomly sample rows with sample_n() and sample_frac()
sample_n(flights, 10)
sample_frac(flights, 0.01)

```

Grouped operations

These verbs are useful on their own, but they become really powerful when you apply them to groups of observations within a dataset.

```{r}
by_tailnum <- group_by(flights, tailnum)
delay <- summarise(by_tailnum, count = n(), dist = mean(distance, na.rm = TRUE), delay = mean(arr_delay, na.rm = TRUE))
delay <- filter(delay, count > 20, dist < 2000)
# average distance flown by a plane.
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
  geom_point(aes(size = count), alpha = 1/2) +
  geom_smooth() +
  scale_size_area()

destinations <- group_by(flights, dest)
summarise(destinations, planes = n_distinct(tailnum), flights = n())

daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
(per_year  <- summarise(per_month, flights = sum(flights)))

# chaining
filter(
  summarise(
    select(
      group_by(flights, year, month, day),
      arr_delay, dep_delay
    ),
    arr = mean(arr_delay, na.rm = TRUE),
    dep = mean(dep_delay, na.rm = TRUE)
  ),
  arr > 30 | dep > 30
)
```